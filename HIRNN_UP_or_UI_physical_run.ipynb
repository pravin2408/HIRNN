{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868b213a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import dependent libraries\n",
    "import os\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from pathlib import Path\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Concatenate, Reshape\n",
    "from keras import optimizers, callbacks\n",
    "from matplotlib import pyplot as plt\n",
    "from datetime import datetime, timedelta\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from tensorflow.keras.initializers import RandomNormal\n",
    "## import required HIRNN\n",
    "from libs.HIRNN_UP import HIRNNLayer, ConvLayer\n",
    "from libs import hirnnutils\n",
    "from keras import initializers, constraints, regularizers\n",
    "from keras.layers import Layer, Dense, Lambda, Activation\n",
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "from keras.layers import Dropout, Activation\n",
    "from keras.regularizers import l2\n",
    "from tensorflow.keras.layers import concatenate \n",
    "from tensorflow.keras.backend import zeros \n",
    "\n",
    "## Ignore all the warnings\n",
    "tf.get_logger().setLevel(logging.ERROR)\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "os.environ['KMP_WARNINGS'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c64cd4b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import time period details\n",
    "stn_data = pd.read_csv('/HIRNN_codes/sample_input_data_HIRNN/unmanaged_intermittent_catchments_time_period_details.csv')\n",
    "stn_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8939311",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train-test split\n",
    "def generate_train_test(train_set, test_set, wrap_length):\n",
    "    train_x_np = train_set.values[:, :-1]\n",
    "    train_y_np = train_set.values[:, -1:]\n",
    "    test_x_np = test_set.values[:, :-1]\n",
    "    test_y_np = test_set.values[:, -1:]\n",
    "    \n",
    "    wrap_number_train = (train_set.shape[0]-wrap_length)//365 + 1\n",
    "    \n",
    "    train_x = np.empty(shape = (wrap_number_train, wrap_length, train_x_np.shape[1]))\n",
    "    train_y = np.empty(shape = (wrap_number_train, wrap_length, train_y_np.shape[1]))\n",
    "\n",
    "    test_x = np.expand_dims(test_x_np, axis=0)\n",
    "    test_y = np.expand_dims(test_y_np, axis=0)\n",
    "    \n",
    "    for i in range(wrap_number_train):\n",
    "        train_x[i, :, :] = train_x_np[i*365:(wrap_length+i*365), :]\n",
    "        train_y[i, :, :] = train_y_np[i*365:(wrap_length+i*365), :]\n",
    "             \n",
    "    return train_x, train_y, test_x, test_y\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393d7153",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(input_shape, seed, num_filters = None, model_type='physical', kernel_size = None, dropout_rate = None):\n",
    "    \"\"\"Create a Keras model with regularization and dropout.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Set seeds for reproducibility\n",
    "    tf.random.set_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # Define input layer\n",
    "    x_input = Input(shape=input_shape, name='Input')\n",
    "    \n",
    "    if model_type == 'physical':\n",
    "        hydro_output = HIRNNLayer(mode= 'normal', name='Hydro')(x_input)\n",
    "        model = Model(x_input, hydro_output)\n",
    "    \n",
    "    elif model_type == 'hybrid':\n",
    "        cnn_output = ConvLayer(filters=num_filters, kernel_size=5, padding='causal', seed=seed, name='Conv1')(x_input)\n",
    "        cnn_output = ConvLayer(filters=1, kernel_size=1, padding='causal', seed=seed, name='Conv2')(cnn_output)\n",
    "        model = Model(x_input, cnn_output)\n",
    "    \n",
    "    return model\n",
    "\n",
    "def train_model(model, train_x, train_y, ep_number, lrate, save_path, seed):\n",
    "    \"\"\"Train a Keras model.\n",
    "    -- model: the Keras model object\n",
    "    -- train_x, train_y: the input and target for training the model\n",
    "    -- ep_number: the maximum epoch number\n",
    "    -- lrate: the initial learning rate\n",
    "    -- save_path: where the model will be saved\n",
    "    \"\"\"\n",
    "     # Set seeds for reproducibility\n",
    "    tf.random.set_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    save = callbacks.ModelCheckpoint(save_path, verbose=0, save_best_only=True, monitor='nse_metrics', mode='max',\n",
    "                                     save_weights_only=True)\n",
    "    es = callbacks.EarlyStopping(monitor='nse_metrics', mode='max', verbose=1, patience=20, min_delta=0.0005,\n",
    "                                 restore_best_weights=True)\n",
    "    reduce = callbacks.ReduceLROnPlateau(monitor='nse_metrics', factor=0.8, patience=5, verbose=1, mode='max',\n",
    "                                         min_delta=0.0005, cooldown=0, min_lr=lrate / 100)\n",
    "    tnan = callbacks.TerminateOnNaN()\n",
    "\n",
    "    model.compile(loss=hirnnutils.nse_loss, metrics=[hirnnutils.nse_metrics], optimizer=optimizers.Adam(learning_rate=lrate))\n",
    "\n",
    "    # Use the shuffled data for training\n",
    "    history = model.fit(train_x, train_y, epochs=ep_number, batch_size=10000, callbacks=[save, es, reduce, tnan], shuffle=False, verbose=0)\n",
    "        \n",
    "    return history\n",
    "\n",
    "def test_model(model, test_x, save_path):\n",
    "    \"\"\"Test a Keras model.\n",
    "    -- model: the Keras model object\n",
    "    -- test_x: the input for testing the model\n",
    "    -- save_path: where the model was saved\n",
    "    \"\"\"\n",
    "    model.load_weights(save_path)  \n",
    "    pred_y = model.predict(test_x, batch_size=10000)\n",
    "    return pred_y    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e02f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# performance metrics\n",
    "def NS(s,o):\n",
    "    \n",
    "    #Nash Sutcliffe efficiency coefficient\n",
    "    #input:\n",
    "        #s: simulated\n",
    "        #o: observed\n",
    "    \n",
    "    return 1 - sum((s-o)**2)/sum((o-np.mean(o))**2)\n",
    "\n",
    "def pc_bias(s,o):\n",
    "\n",
    "#     Percent Bias\n",
    "#     input:\n",
    "#         s: simulated\n",
    "#         o: observed\n",
    "\n",
    "    return 100.0*sum(o-s)/sum(o)\n",
    "def rmse(s,o):\n",
    "\n",
    "#     Root Mean Squared Error\n",
    "#     input:\n",
    "#         s: simulated\n",
    "#         o: observed\n",
    "\n",
    "    return np.sqrt(np.mean((s-o)**2))\n",
    "\n",
    "\n",
    "def kge(s,o):\n",
    "    \n",
    "#     Kling Gupta Efficiency \n",
    "#     input:\n",
    "#         s: simulated\n",
    "#         o: observed\n",
    "    \n",
    "    alpha = np.std(s)/np.std(o)\n",
    "    beta = np.mean(s)/np.mean(o)\n",
    "    return 1-((1 - np.corrcoef(s,o)[0,1])**2 + (alpha - 1)**2 + (beta - 1)**2)**0.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3e2894-86fe-4931-8bb4-f7df4aeb966b",
   "metadata": {},
   "outputs": [],
   "source": [
    "perform = pd.DataFrame()\n",
    "perform_list = []\n",
    "perform[['Station']] = \"\"\n",
    "perform[['NSE_val', 'PBIAS_val', 'RMSE_val', 'KGE_val']] = \"\"\n",
    "\n",
    "for stn in range(0, len(stn_data)): \n",
    "    station = stn_data['gauge_id'][stn]\n",
    "    cat_file = str(station) + str('_input_data.csv')\n",
    "    hirnn_data = pd.read_csv('/HIRNN_codes/sample_input_data_HIRNN/'+ cat_file)\n",
    "    hirnn_data['Date'] = pd.to_datetime(hirnn_data['Date'])\n",
    "\n",
    "    # Keep only the specified columns\n",
    "    hirnn_data = hirnn_data[['Date', 'Pptn', 'PET', 'streamflow_mm']]\n",
    "    hirnn_data.set_index('Date', inplace=True)\n",
    "    PRNN_cal_start = stn_data['warm_up_cal_start'][stn]\n",
    "    cal_end = stn_data['cal_end'][stn] \n",
    "    PRNN_val_start = stn_data['warm_up_val_start'][stn] \n",
    "    val_end = stn_data['val_end'][stn] \n",
    "    val_start = stn_data['val_start'][stn] \n",
    "    ####################\n",
    "    #  Period set up   #\n",
    "    ####################\n",
    "\n",
    "    training_start = PRNN_cal_start\n",
    "    training_end= cal_end\n",
    "\n",
    "    testing_start = PRNN_val_start \n",
    "    testing_end= val_end\n",
    "\n",
    "    # Split data set to training_set and testing_set\n",
    "    train_set = hirnn_data[hirnn_data.index.isin(pd.date_range(training_start, training_end))]\n",
    "    test_set = hirnn_data[hirnn_data.index.isin(pd.date_range(testing_start, testing_end))]\n",
    "\n",
    "    print(f\"The training data set is from {training_start} to {training_end}, with a shape of {train_set.shape}\")\n",
    "    print(f\"The testing data set is from {testing_start} to {testing_end}, with a shape of {test_set.shape}\")\n",
    "    wrap_length= 2922 # It can be other values, but recommend this value should not be less than 5 years (1826 days).\n",
    "    train_x, train_y, test_x, test_y = generate_train_test(train_set, test_set, wrap_length=wrap_length)\n",
    "\n",
    "    print(f'The shape of train_x, train_y, test_x, and test_y after wrapping by {wrap_length} days are:')\n",
    "    print(f'{train_x.shape}, {train_y.shape}, {test_x.shape}, and {test_y.shape}')\n",
    "   \n",
    "\n",
    "\n",
    "    basin_id =  str(station) + str('_HIRNN_UP') \n",
    "    save_path_hirnn = f'/HIRNN_codes/{basin_id}_physical.weights.h5' # use desired path\n",
    "\n",
    "\n",
    "    model = create_model((train_x.shape[1], train_x.shape[2]), seed = 200, num_filters = 8, model_type='physical')\n",
    "    model.summary()\n",
    "    hybrid_history = train_model(model, train_x, train_y, ep_number=200, seed = 200, lrate=0.01, save_path=save_path_hirnn)\n",
    "    ####################\n",
    "    # Physical NN model#\n",
    "    ####################\n",
    "    model = create_model((test_x.shape[1], test_x.shape[2]), seed = 200, num_filters = 8, model_type='physical')\n",
    "    Q_hirnn = test_model(model, test_x, save_path_hirnn)\n",
    "    Q_hirnn = test_model(model, test_x, save_path_hirnn)\n",
    "    evaluate_set = test_set.loc[:, ['Pptn', 'PET', 'streamflow_mm']]\n",
    "    evaluate_set['Q_obs'] = evaluate_set['streamflow_mm']\n",
    "    evaluate_set['Q_hirnn'] = np.clip(Q_hirnn[0, :, :], a_min = 0, a_max = None)\n",
    "    evaluate_set = evaluate_set.loc[val_start:val_end]\n",
    "    evaluate_set = evaluate_set.fillna(0)\n",
    "    NSE_val = NS(evaluate_set['Q_hirnn'],evaluate_set['Q_obs'])\n",
    "    PBIAS_val = pc_bias(evaluate_set['Q_hirnn'],evaluate_set['Q_obs'])\n",
    "    RMSE_val = rmse(evaluate_set['Q_hirnn'],evaluate_set['Q_obs'])\n",
    "    KGE_val = kge(evaluate_set['Q_hirnn'],evaluate_set['Q_obs'])    \n",
    "    perform_data = {\n",
    "        'Station': station,\n",
    "        'NSE_val': NSE_val,\n",
    "        'PBIAS_val': PBIAS_val,\n",
    "        'RMSE_val': RMSE_val,\n",
    "        'KGE_val': KGE_val\n",
    "    }\n",
    "    print(perform_data)\n",
    "    perform_df = pd.DataFrame(perform_data, index=[0])\n",
    "    perform_list.append(perform_df)\n",
    "\n",
    "# Concatenate all dataframes in the list into one dataframe\n",
    "perform = pd.concat(perform_list, ignore_index=True)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee457520-a50a-46d3-9ecb-9fb6e034629e",
   "metadata": {},
   "outputs": [],
   "source": [
    "perform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9102f5fc-92c2-490a-bc38-ae8d3bf0add8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

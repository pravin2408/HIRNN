{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "868b213a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-20 13:03:18.558419: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-12-20 13:03:18.615317: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-12-20 13:03:18.617188: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-12-20 13:03:19.494718: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "## Import dependent libraries\n",
    "import os\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from pathlib import Path\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Concatenate, Reshape\n",
    "from keras import optimizers, callbacks\n",
    "from matplotlib import pyplot as plt\n",
    "from datetime import datetime, timedelta\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from tensorflow.keras.initializers import RandomNormal\n",
    "## import required HIRNN\n",
    "from libs.HIRNN_UP import HIRNNLayer, ConvLayer\n",
    "from libs import hirnnutils\n",
    "from keras import initializers, constraints, regularizers\n",
    "from keras.layers import Layer, Dense, Lambda, Activation\n",
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "from keras.layers import Dropout, Activation\n",
    "from keras.regularizers import l2\n",
    "from tensorflow.keras.layers import concatenate \n",
    "from tensorflow.keras.backend import zeros\n",
    "import random\n",
    "## Ignore all the warnings\n",
    "tf.get_logger().setLevel(logging.ERROR)\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "os.environ['KMP_WARNINGS'] = '0'\n",
    "tf.config.experimental.enable_op_determinism()\n",
    "os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
    "os.environ['TF_CUDNN_DETERMINISTIC'] = '1'\n",
    "tf.config.optimizer.set_experimental_options({'cudnn_deterministic': True})\n",
    "# Fix seeds for reproducibility\n",
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Enable deterministic operations\n",
    "tf.config.experimental.enable_op_determinism()\n",
    "tf.config.optimizer.set_experimental_options({'cudnn_deterministic': True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c64cd4b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gauge_id</th>\n",
       "      <th>warm_up_cal_start</th>\n",
       "      <th>warm_up_cal_end</th>\n",
       "      <th>cal_start</th>\n",
       "      <th>cal_end</th>\n",
       "      <th>warm_up_val_start</th>\n",
       "      <th>warm_up_val_end</th>\n",
       "      <th>val_start</th>\n",
       "      <th>val_end</th>\n",
       "      <th>area_km2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>404207</td>\n",
       "      <td>1989-01-01</td>\n",
       "      <td>1991-12-31</td>\n",
       "      <td>1992-01-01</td>\n",
       "      <td>2001-12-31</td>\n",
       "      <td>2002-01-01</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>2005-01-01</td>\n",
       "      <td>2009-12-31</td>\n",
       "      <td>454.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>606185</td>\n",
       "      <td>1978-01-01</td>\n",
       "      <td>1980-12-31</td>\n",
       "      <td>1981-01-01</td>\n",
       "      <td>1990-12-31</td>\n",
       "      <td>1991-01-01</td>\n",
       "      <td>1993-12-31</td>\n",
       "      <td>1994-01-01</td>\n",
       "      <td>1998-12-31</td>\n",
       "      <td>379.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gauge_id warm_up_cal_start warm_up_cal_end   cal_start     cal_end  \\\n",
       "0    404207        1989-01-01      1991-12-31  1992-01-01  2001-12-31   \n",
       "1    606185        1978-01-01      1980-12-31  1981-01-01  1990-12-31   \n",
       "\n",
       "  warm_up_val_start warm_up_val_end   val_start     val_end  area_km2  \n",
       "0        2002-01-01      2004-12-31  2005-01-01  2009-12-31     454.7  \n",
       "1        1991-01-01      1993-12-31  1994-01-01  1998-12-31     379.4  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stn_data = pd.read_csv('/HIRNN_codes/sample_input_data_HIRNN/unmanaged_intermittent_catchments_time_period_details.csv')\n",
    "stn_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b8939311",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_train_test(train_set, test_set, wrap_length):\n",
    "    train_x_np = train_set.values[:, :-1]\n",
    "    train_y_np = train_set.values[:, -1:]\n",
    "    test_x_np = test_set.values[:, :-1]\n",
    "    test_y_np = test_set.values[:, -1:]\n",
    "    \n",
    "    wrap_number_train = (train_set.shape[0]-wrap_length)//365 + 1\n",
    "    \n",
    "    train_x = np.empty(shape = (wrap_number_train, wrap_length, train_x_np.shape[1]))\n",
    "    train_y = np.empty(shape = (wrap_number_train, wrap_length, train_y_np.shape[1]))\n",
    "\n",
    "    test_x = np.expand_dims(test_x_np, axis=0)\n",
    "    test_y = np.expand_dims(test_y_np, axis=0)\n",
    "    \n",
    "    for i in range(wrap_number_train):\n",
    "        train_x[i, :, :] = train_x_np[i*365:(wrap_length+i*365), :]\n",
    "        train_y[i, :, :] = train_y_np[i*365:(wrap_length+i*365), :]\n",
    "             \n",
    "    return train_x, train_y, test_x, test_y\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "393d7153",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(input_shape, seed, num_filters = None, model_type='hybrid', kernel_size = None, dropout_rate = None):\n",
    "    \"\"\"Create a Keras model with regularization and dropout.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Set seeds for reproducibility\n",
    "    tf.random.set_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # Define input layer\n",
    "    x_input = Input(shape=input_shape, name='Input')\n",
    "    \n",
    "    if model_type == 'physical':\n",
    "        hydro_output = PRNNLayer(mode= 'normal', name='Hydro')(x_input)\n",
    "        model = Model(x_input, hydro_output)\n",
    "    \n",
    "    elif model_type == 'hybrid':\n",
    "        cnn_output = ConvLayer(filters=num_filters_input, kernel_size=kernel_size_input, padding='causal', seed=seed, name='Conv1')(x_input)\n",
    "        cnn_output = Dropout(dropout_rate, seed=seed)(cnn_output)\n",
    "        cnn_output = ConvLayer(filters=1, kernel_size=1, padding='causal', seed=seed, name='Conv2')(cnn_output)\n",
    "        model = Model(x_input, cnn_output)\n",
    "    \n",
    "    return model\n",
    "\n",
    "def train_model(model, train_x, train_y, ep_number, lrate, save_path, seed):\n",
    "\n",
    "#      train_x, train_y: the input and target for training the model\n",
    "#      ep_number: the maximum epoch number\n",
    "#     lrate: the initial learning rate\n",
    "#     save_path: where the model will be saved\n",
    " \n",
    "     # Set seeds for reproducibility\n",
    "    tf.random.set_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    save = callbacks.ModelCheckpoint(save_path, verbose=0, save_best_only=True, monitor='nse_metrics', mode='max',\n",
    "                                     save_weights_only=True)\n",
    "    es = callbacks.EarlyStopping(monitor='nse_metrics', mode='max', verbose=0, patience=20, min_delta=0.0005,\n",
    "                                 restore_best_weights=True)\n",
    "    reduce = callbacks.ReduceLROnPlateau(monitor='nse_metrics', factor=0.8, patience=5, verbose=0, mode='max',\n",
    "                                         min_delta=0.0005, cooldown=0, min_lr=lrate / 100)\n",
    "    tnan = callbacks.TerminateOnNaN()\n",
    "    model.compile(loss=hirnnutils.nse_loss, metrics=[hirnnutils.nse_metrics], optimizer=optimizers.Adam(learning_rate=lrate))\n",
    "\n",
    "    # Use the shuffled data for training\n",
    "    history = model.fit(train_x, train_y, epochs=ep_number, batch_size=10000, callbacks=[save, es, reduce, tnan], shuffle=False, verbose=0)\n",
    "    \n",
    "    return history\n",
    "\n",
    "def test_model(model, test_x, save_path):\n",
    "    \"\"\"Test a Keras model.\n",
    "    -- model: the Keras model object\n",
    "    -- test_x: the input for testing the model\n",
    "    -- save_path: where the model was saved\n",
    "    \"\"\"\n",
    "    model.load_weights(save_path)  # Remove by_name=True\n",
    "    pred_y = model.predict(test_x, batch_size=10000)\n",
    "    return pred_y    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "48e02f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def NS(s,o):\n",
    "    \n",
    "    #Nash Sutcliffe efficiency coefficient\n",
    "    #input:\n",
    "        #s: simulated\n",
    "        #o: observed\n",
    "    \n",
    "    return 1 - sum((s-o)**2)/sum((o-np.mean(o))**2)\n",
    "\n",
    "def pc_bias(s,o):\n",
    "\n",
    "#     Percent Bias\n",
    "#     input:\n",
    "#         s: simulated\n",
    "#         o: observed\n",
    "\n",
    "    return 100.0*sum(o-s)/sum(o)\n",
    "def rmse(s,o):\n",
    "\n",
    "#     Root Mean Squared Error\n",
    "#     input:\n",
    "#         s: simulated\n",
    "#         o: observed\n",
    "\n",
    "    return np.sqrt(np.mean((s-o)**2))\n",
    "\n",
    "\n",
    "def kge(s,o):\n",
    "    \n",
    "#     Kling Gupta Efficiency \n",
    "#     input:\n",
    "#         s: simulated\n",
    "#         o: observed\n",
    "    \n",
    "    alpha = np.std(s)/np.std(o)\n",
    "    beta = np.mean(s)/np.mean(o)\n",
    "    return 1-((1 - np.corrcoef(s,o)[0,1])**2 + (alpha - 1)**2 + (beta - 1)**2)**0.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "963c81ec-44ea-4edb-bc54-57d934d64f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(data):\n",
    "    data_mean = np.mean(data, axis=-2, keepdims=True)\n",
    "    data_std = np.std(data, axis=-2, keepdims=True)\n",
    "    data_scaled = (data - data_mean) / data_std\n",
    "    return data_scaled, data_mean, data_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5149c39a-a404-4010-a8b4-55536b01e9a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "404207\n",
      "dropout_rate_input: 0.1\n",
      "kernel_size_input: 5\n",
      "num_filters_input: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-20 13:03:21.357033: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1960] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 125ms/step\n",
      "num_filters_input: 4\n",
      "1/1 [==============================] - 0s 85ms/step\n",
      "num_filters_input: 8\n",
      "1/1 [==============================] - 0s 87ms/step\n",
      "num_filters_input: 16\n",
      "1/1 [==============================] - 0s 81ms/step\n",
      "num_filters_input: 32\n",
      "1/1 [==============================] - 0s 83ms/step\n",
      "kernel_size_input: 10\n",
      "num_filters_input: 2\n",
      "1/1 [==============================] - 0s 82ms/step\n",
      "num_filters_input: 4\n",
      "1/1 [==============================] - 0s 83ms/step\n",
      "num_filters_input: 8\n",
      "1/1 [==============================] - 0s 84ms/step\n",
      "num_filters_input: 16\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "num_filters_input: 32\n",
      "1/1 [==============================] - 0s 84ms/step\n",
      "kernel_size_input: 15\n",
      "num_filters_input: 2\n",
      "1/1 [==============================] - 0s 85ms/step\n",
      "num_filters_input: 4\n",
      "1/1 [==============================] - 0s 86ms/step\n",
      "num_filters_input: 8\n",
      "1/1 [==============================] - 0s 83ms/step\n",
      "num_filters_input: 16\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "num_filters_input: 32\n",
      "1/1 [==============================] - 0s 82ms/step\n",
      "kernel_size_input: 20\n",
      "num_filters_input: 2\n",
      "1/1 [==============================] - 0s 84ms/step\n",
      "num_filters_input: 4\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "num_filters_input: 8\n",
      "1/1 [==============================] - 0s 88ms/step\n",
      "num_filters_input: 16\n",
      "1/1 [==============================] - 0s 85ms/step\n",
      "num_filters_input: 32\n",
      "1/1 [==============================] - 0s 84ms/step\n"
     ]
    }
   ],
   "source": [
    "perform = pd.DataFrame()\n",
    "perform_list = []\n",
    "perform[['Station','Dropout_rate', 'Kernel_size', 'Number_of_filters']] = \"\"\n",
    "perform[['NSE_val', 'PBIAS_val', 'RMSE_val', 'KGE_val']] = \"\"\n",
    "for stn in range(0, len(stn_data)):\n",
    "    station = stn_data['gauge_id'][stn]\n",
    "    print(station)\n",
    "    hirnn_data = pd.read_csv('HIRNN_output.csv') # use HIRNN output data for both training and testing period\n",
    "    hirnn_data['Date'] = pd.to_datetime(hirnn_data['Date'])\n",
    "\n",
    "    # Keep only the specified columns\n",
    "    hirnn_data = hirnn_data[['Date', 'Pptn', 'PET', 'flow_physical', 'streamflow_mm']]\n",
    "    hirnn_data.set_index('Date', inplace=True)\n",
    "    PRNN_cal_start = stn_data['warm_up_cal_start'][stn]\n",
    "    cal_start = stn_data['cal_start'][stn] \n",
    "    cal_end = stn_data['cal_end'][stn] \n",
    "    PRNN_val_start = stn_data['warm_up_val_start'][stn] \n",
    "    val_end = stn_data['val_end'][stn] \n",
    "    val_start = stn_data['val_start'][stn] \n",
    "    ####################\n",
    "    #  Period set up   #\n",
    "    ####################\n",
    "\n",
    "    training_start = PRNN_cal_start\n",
    "    training_end= cal_end\n",
    "\n",
    "    testing_start = PRNN_val_start\n",
    "    testing_end= val_end\n",
    "\n",
    "    # Split data set to training_set and testing_set\n",
    "    train_set = hirnn_data[hirnn_data.index.isin(pd.date_range(training_start, training_end))]\n",
    "    test_set = hirnn_data[hirnn_data.index.isin(pd.date_range(testing_start, testing_end))]\n",
    "\n",
    "    wrap_length= 2922 # It can be other values, but recommend this value should not be less than 5 years (1826 days).\n",
    "    train_x, train_y, test_x, test_y = generate_train_test(train_set, test_set, wrap_length=wrap_length)\n",
    "\n",
    "    dropout_rates = [0.1, 0.2, 0.3, 0.4, 0.5]\n",
    "    for dropout in range(0, len(dropout_rates)):  \n",
    "        dropout_rate_input = dropout_rates[dropout]\n",
    "        print('dropout_rate_input:',dropout_rate_input)\n",
    "        kernel_sizes = [5, 10, 15, 20]\n",
    "        for kernel in range(0, len(kernel_sizes)): \n",
    "            kernel_size_input = int(kernel_sizes[kernel])\n",
    "            print('kernel_size_input:',kernel_size_input)\n",
    "            num_filters = [2, 4, 8, 16, 32]\n",
    "            for filter_size in range(0, len(num_filters)): \n",
    "                num_filters_input = int(num_filters[filter_size])\n",
    "                print('num_filters_input:',num_filters_input)\n",
    "\n",
    "                basin_id = str(station) + str('_HIRNN_droput_') + str(dropout_rate_input) + str('_kernel_size_') + str(kernel_size_input) + str('_filter_size_') + str(num_filters_input) \n",
    "                save_path_hybrid = f'/HIRNN_codes/{basin_id}_hybrid.weights.h5'# use desired path\n",
    "\n",
    "                \n",
    "                model = create_model((train_x.shape[1], train_x.shape[2]), seed = 200, num_filters = num_filters_input, model_type='hybrid', kernel_size=kernel_size_input, dropout_rate=dropout_rate_input)\n",
    "                #model.summary()\n",
    "\n",
    "                train_x_nor, train_x_mean, train_x_std = normalize(train_x)\n",
    "                train_y_nor, train_y_mean, train_y_std = normalize(train_y)\n",
    "\n",
    "                hybrid_history = train_model(model, train_x_nor, train_y_nor,ep_number=200, lrate=0.01, save_path=save_path_hybrid, seed = 200)\n",
    "                \n",
    "                ####################\n",
    "                #  Hybrid NN model #\n",
    "                ####################\n",
    "                model = create_model((test_x.shape[1], test_x.shape[2]), seed = 200, num_filters = num_filters_input, model_type='hybrid', kernel_size=kernel_size_input, dropout_rate=dropout_rate_input)\n",
    "                #We use the feature means/stds of the training period for normalization\n",
    "                test_x_nor = (test_x - train_x_mean) / train_x_std \n",
    "                Q_hybrid = test_model(model, test_x_nor, save_path_hybrid)\n",
    "                #We use the feature means/stds of the training period for recovery\n",
    "                Q_hybrid = Q_hybrid * train_y_std + train_y_mean\n",
    "                evaluate_set = test_set.loc[:, ['Pptn', 'PET', 'streamflow_mm']]\n",
    "                evaluate_set['Q_obs'] = evaluate_set['streamflow_mm']\n",
    "                evaluate_set['Q_hybrid'] = np.clip(Q_hybrid[0, :, :], a_min = 0, a_max = None)\n",
    "                evaluate_set = evaluate_set.loc[val_start:val_end]\n",
    "                evaluate_set = evaluate_set.fillna(0)\n",
    "                NSE_val = NS(evaluate_set['Q_hybrid'],evaluate_set['Q_obs'])\n",
    "                PBIAS_val = pc_bias(evaluate_set['Q_hybrid'],evaluate_set['Q_obs'])\n",
    "                RMSE_val = rmse(evaluate_set['Q_hybrid'],evaluate_set['Q_obs'])\n",
    "                KGE_val = kge(evaluate_set['Q_hybrid'],evaluate_set['Q_obs'])    \n",
    "                perform_data = {\n",
    "                    'Station': station,\n",
    "                    'Dropout_rate':dropout_rate_input, \n",
    "                    'Kernel_size': kernel_size_input, \n",
    "                    'Number_of_filters': num_filters_input,\n",
    "                    'NSE_val': NSE_val,\n",
    "                    'PBIAS_val': PBIAS_val,\n",
    "                    'RMSE_val': RMSE_val,\n",
    "                    'KGE_val': KGE_val\n",
    "                }\n",
    "                #print(perform_data)\n",
    "                perform_df = pd.DataFrame(perform_data, index=[0])\n",
    "                perform_list.append(perform_df)\n",
    "\n",
    "            # Concatenate all dataframes in the list into one dataframe\n",
    "            perform = pd.concat(perform_list, ignore_index=True)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be5efb4c-9b14-4a82-9390-c3d1fb5bb028",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Station</th>\n",
       "      <th>Dropout_rate</th>\n",
       "      <th>Kernel_size</th>\n",
       "      <th>Number_of_filters</th>\n",
       "      <th>NSE_val</th>\n",
       "      <th>PBIAS_val</th>\n",
       "      <th>RMSE_val</th>\n",
       "      <th>KGE_val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>404207</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.459197</td>\n",
       "      <td>-108.931453</td>\n",
       "      <td>0.386816</td>\n",
       "      <td>-0.148492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>404207</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0.507860</td>\n",
       "      <td>-80.808713</td>\n",
       "      <td>0.369003</td>\n",
       "      <td>0.128513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>404207</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>0.473110</td>\n",
       "      <td>-85.913767</td>\n",
       "      <td>0.381808</td>\n",
       "      <td>0.071240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>404207</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "      <td>0.581186</td>\n",
       "      <td>-96.182307</td>\n",
       "      <td>0.340405</td>\n",
       "      <td>-0.003884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>404207</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5</td>\n",
       "      <td>32</td>\n",
       "      <td>0.632805</td>\n",
       "      <td>-101.932313</td>\n",
       "      <td>0.318738</td>\n",
       "      <td>-0.044249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>404207</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>0.628637</td>\n",
       "      <td>-80.246296</td>\n",
       "      <td>0.320541</td>\n",
       "      <td>0.175519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>404207</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>0.537678</td>\n",
       "      <td>-76.923446</td>\n",
       "      <td>0.357649</td>\n",
       "      <td>0.176699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>404207</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>0.559550</td>\n",
       "      <td>-87.550549</td>\n",
       "      <td>0.349087</td>\n",
       "      <td>0.076253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>404207</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10</td>\n",
       "      <td>16</td>\n",
       "      <td>0.641916</td>\n",
       "      <td>-84.814454</td>\n",
       "      <td>0.314759</td>\n",
       "      <td>0.121495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>404207</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10</td>\n",
       "      <td>32</td>\n",
       "      <td>0.661180</td>\n",
       "      <td>-93.601135</td>\n",
       "      <td>0.306175</td>\n",
       "      <td>0.040127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>404207</td>\n",
       "      <td>0.1</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>0.669332</td>\n",
       "      <td>-64.910306</td>\n",
       "      <td>0.302469</td>\n",
       "      <td>0.330063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>404207</td>\n",
       "      <td>0.1</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>0.619688</td>\n",
       "      <td>-62.947528</td>\n",
       "      <td>0.324381</td>\n",
       "      <td>0.319626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>404207</td>\n",
       "      <td>0.1</td>\n",
       "      <td>15</td>\n",
       "      <td>8</td>\n",
       "      <td>0.684237</td>\n",
       "      <td>-78.472288</td>\n",
       "      <td>0.295574</td>\n",
       "      <td>0.189528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>404207</td>\n",
       "      <td>0.1</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>0.651587</td>\n",
       "      <td>-88.768975</td>\n",
       "      <td>0.310479</td>\n",
       "      <td>0.088739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>404207</td>\n",
       "      <td>0.1</td>\n",
       "      <td>15</td>\n",
       "      <td>32</td>\n",
       "      <td>0.687196</td>\n",
       "      <td>-87.911116</td>\n",
       "      <td>0.294185</td>\n",
       "      <td>0.103391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>404207</td>\n",
       "      <td>0.1</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>0.637889</td>\n",
       "      <td>-65.559840</td>\n",
       "      <td>0.316523</td>\n",
       "      <td>0.320722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>404207</td>\n",
       "      <td>0.1</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>0.651381</td>\n",
       "      <td>-73.807476</td>\n",
       "      <td>0.310571</td>\n",
       "      <td>0.228419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>404207</td>\n",
       "      <td>0.1</td>\n",
       "      <td>20</td>\n",
       "      <td>8</td>\n",
       "      <td>0.656463</td>\n",
       "      <td>-82.166747</td>\n",
       "      <td>0.308299</td>\n",
       "      <td>0.150509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>404207</td>\n",
       "      <td>0.1</td>\n",
       "      <td>20</td>\n",
       "      <td>16</td>\n",
       "      <td>0.657943</td>\n",
       "      <td>-85.185221</td>\n",
       "      <td>0.307634</td>\n",
       "      <td>0.127960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>404207</td>\n",
       "      <td>0.1</td>\n",
       "      <td>20</td>\n",
       "      <td>32</td>\n",
       "      <td>0.664851</td>\n",
       "      <td>-85.188168</td>\n",
       "      <td>0.304512</td>\n",
       "      <td>0.128129</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Station  Dropout_rate  Kernel_size  Number_of_filters   NSE_val  \\\n",
       "0    404207           0.1            5                  2  0.459197   \n",
       "1    404207           0.1            5                  4  0.507860   \n",
       "2    404207           0.1            5                  8  0.473110   \n",
       "3    404207           0.1            5                 16  0.581186   \n",
       "4    404207           0.1            5                 32  0.632805   \n",
       "5    404207           0.1           10                  2  0.628637   \n",
       "6    404207           0.1           10                  4  0.537678   \n",
       "7    404207           0.1           10                  8  0.559550   \n",
       "8    404207           0.1           10                 16  0.641916   \n",
       "9    404207           0.1           10                 32  0.661180   \n",
       "10   404207           0.1           15                  2  0.669332   \n",
       "11   404207           0.1           15                  4  0.619688   \n",
       "12   404207           0.1           15                  8  0.684237   \n",
       "13   404207           0.1           15                 16  0.651587   \n",
       "14   404207           0.1           15                 32  0.687196   \n",
       "15   404207           0.1           20                  2  0.637889   \n",
       "16   404207           0.1           20                  4  0.651381   \n",
       "17   404207           0.1           20                  8  0.656463   \n",
       "18   404207           0.1           20                 16  0.657943   \n",
       "19   404207           0.1           20                 32  0.664851   \n",
       "\n",
       "     PBIAS_val  RMSE_val   KGE_val  \n",
       "0  -108.931453  0.386816 -0.148492  \n",
       "1   -80.808713  0.369003  0.128513  \n",
       "2   -85.913767  0.381808  0.071240  \n",
       "3   -96.182307  0.340405 -0.003884  \n",
       "4  -101.932313  0.318738 -0.044249  \n",
       "5   -80.246296  0.320541  0.175519  \n",
       "6   -76.923446  0.357649  0.176699  \n",
       "7   -87.550549  0.349087  0.076253  \n",
       "8   -84.814454  0.314759  0.121495  \n",
       "9   -93.601135  0.306175  0.040127  \n",
       "10  -64.910306  0.302469  0.330063  \n",
       "11  -62.947528  0.324381  0.319626  \n",
       "12  -78.472288  0.295574  0.189528  \n",
       "13  -88.768975  0.310479  0.088739  \n",
       "14  -87.911116  0.294185  0.103391  \n",
       "15  -65.559840  0.316523  0.320722  \n",
       "16  -73.807476  0.310571  0.228419  \n",
       "17  -82.166747  0.308299  0.150509  \n",
       "18  -85.185221  0.307634  0.127960  \n",
       "19  -85.188168  0.304512  0.128129  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7321f9fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
